{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "exceptional-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split # 일정 비율로 학습셋과 테스트셋을 구분\n",
    "from tensorflow.keras.models import load_model # 모델 사용\n",
    "from sklearn.model_selection import StratifiedKFold # 데이터를 각각 쪼개 학습셋 과 테스트셋으로 사용\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../../../../dlevery/dataset/sonar.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "direct-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "collaborative-liberia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "\n",
      "       9   ...      51      52      53      54      55      56      57  \\\n",
      "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
      "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
      "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
      "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
      "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
      "\n",
      "       58      59  60  \n",
      "0  0.0090  0.0032   R  \n",
      "1  0.0052  0.0044   R  \n",
      "2  0.0095  0.0078   R  \n",
      "3  0.0040  0.0117   R  \n",
      "4  0.0107  0.0094   R  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "endless-attention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5913\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6250\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6587\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7067\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7644\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7500\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7644\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7740\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7788\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7788\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8029\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7981\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8221\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8077\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.7933\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8317\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8413\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8125\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8413\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8125\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8365\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8558\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8510\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.8606\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8510\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8510\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8413\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8654\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8606\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8750\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.8654\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8510\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.8894\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8462\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8750\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8654\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2824 - accuracy: 0.8990\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8846\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.9038\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.8990\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8894\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.9038\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 0.8846\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8942\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.8894\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9327\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.9279\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2417 - accuracy: 0.9183\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9231\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9279\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9135\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9375\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9038\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9327\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9087\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9231\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9375\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9231\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9279\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9231\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1930 - accuracy: 0.9231\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.9038\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9567\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1813 - accuracy: 0.9423\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9519\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9471\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1833 - accuracy: 0.9279\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9471\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9471\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9567\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.9471\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9615\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9519\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9615\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9471\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9423\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9519\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9663\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9471\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9567\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9471\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1357 - accuracy: 0.9567\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9615\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9471\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9567\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9567\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9663\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9327\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9712\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9615\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9663\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.9519\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9663\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9760\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9808\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9663\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9615\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1007 - accuracy: 0.9663\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9663\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9808\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9808\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9808\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9712\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9712\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9856\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9712\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9760\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9808\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9760\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9856\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9615\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9808\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9808\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9856\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9856\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9808\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9712\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9760\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9760\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9856\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9952\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9904\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9856\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9952\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9952\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9904\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9904\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9856\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9904\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9904\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9952\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9952\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9904\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9952\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9952\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9952\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9952\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9952\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9952\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9952\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9904\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9952\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9952\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9952\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9952\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9952\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9904\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9952\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "\n",
      " accracy : 1.0000\n"
     ]
    }
   ],
   "source": [
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "dataset = df.values\n",
    "x = dataset[:, 0:60].astype(float)\n",
    "y_obj = dataset[:, 60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(y_obj)\n",
    "y = e.transform(y_obj)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 60, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x, y, epochs = 200, batch_size = 5) # overfiting 발생\n",
    "\n",
    "print(\"\\n accracy : %.04f\" % (model.evaluate(x, y)[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "suburban-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 2/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9379\n",
      "Epoch 3/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9793\n",
      "Epoch 4/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9793\n",
      "Epoch 5/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9724\n",
      "Epoch 6/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9862\n",
      "Epoch 7/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 8/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 8.3396e-04 - accuracy: 1.0000\n",
      "Epoch 9/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 7.2945e-04 - accuracy: 1.0000\n",
      "Epoch 10/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 6.8337e-04 - accuracy: 1.0000\n",
      "Epoch 11/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 6.7752e-04 - accuracy: 1.0000\n",
      "Epoch 12/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 6.4168e-04 - accuracy: 1.0000\n",
      "Epoch 13/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 6.2144e-04 - accuracy: 1.0000\n",
      "Epoch 14/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.9926e-04 - accuracy: 1.0000\n",
      "Epoch 15/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.8805e-04 - accuracy: 1.0000\n",
      "Epoch 16/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.7702e-04 - accuracy: 1.0000\n",
      "Epoch 17/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.5738e-04 - accuracy: 1.0000\n",
      "Epoch 18/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.4387e-04 - accuracy: 1.0000\n",
      "Epoch 19/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.5286e-04 - accuracy: 1.0000\n",
      "Epoch 20/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.2766e-04 - accuracy: 1.0000\n",
      "Epoch 21/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.1314e-04 - accuracy: 1.0000\n",
      "Epoch 22/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.1828e-04 - accuracy: 1.0000\n",
      "Epoch 23/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 5.0161e-04 - accuracy: 1.0000\n",
      "Epoch 24/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.9317e-04 - accuracy: 1.0000\n",
      "Epoch 25/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.7775e-04 - accuracy: 1.0000\n",
      "Epoch 26/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.6630e-04 - accuracy: 1.0000\n",
      "Epoch 27/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.6148e-04 - accuracy: 1.0000\n",
      "Epoch 28/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.5602e-04 - accuracy: 1.0000\n",
      "Epoch 29/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.4791e-04 - accuracy: 1.0000\n",
      "Epoch 30/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.3835e-04 - accuracy: 1.0000\n",
      "Epoch 31/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.3081e-04 - accuracy: 1.0000\n",
      "Epoch 32/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.2607e-04 - accuracy: 1.0000\n",
      "Epoch 33/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.1839e-04 - accuracy: 1.0000\n",
      "Epoch 34/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.1538e-04 - accuracy: 1.0000\n",
      "Epoch 35/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.0001e-04 - accuracy: 1.0000\n",
      "Epoch 36/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.9419e-04 - accuracy: 1.0000\n",
      "Epoch 37/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.8160e-04 - accuracy: 1.0000\n",
      "Epoch 38/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.7453e-04 - accuracy: 1.0000\n",
      "Epoch 39/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.6814e-04 - accuracy: 1.0000\n",
      "Epoch 40/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.6489e-04 - accuracy: 1.0000\n",
      "Epoch 41/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.5211e-04 - accuracy: 1.0000\n",
      "Epoch 42/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.4785e-04 - accuracy: 1.0000\n",
      "Epoch 43/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.4301e-04 - accuracy: 1.0000\n",
      "Epoch 44/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.3620e-04 - accuracy: 1.0000\n",
      "Epoch 45/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.3248e-04 - accuracy: 1.0000\n",
      "Epoch 46/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.2781e-04 - accuracy: 1.0000\n",
      "Epoch 47/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.2442e-04 - accuracy: 1.0000\n",
      "Epoch 48/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.2410e-04 - accuracy: 1.0000\n",
      "Epoch 49/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.1440e-04 - accuracy: 1.0000\n",
      "Epoch 50/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.1333e-04 - accuracy: 1.0000\n",
      "Epoch 51/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.0821e-04 - accuracy: 1.0000\n",
      "Epoch 52/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.0799e-04 - accuracy: 1.0000\n",
      "Epoch 53/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.0078e-04 - accuracy: 1.0000\n",
      "Epoch 54/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.9722e-04 - accuracy: 1.0000\n",
      "Epoch 55/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.9187e-04 - accuracy: 1.0000\n",
      "Epoch 56/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.9770e-04 - accuracy: 1.0000\n",
      "Epoch 57/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.9064e-04 - accuracy: 1.0000\n",
      "Epoch 58/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.8788e-04 - accuracy: 1.0000\n",
      "Epoch 59/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.8677e-04 - accuracy: 1.0000\n",
      "Epoch 60/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.7879e-04 - accuracy: 1.0000\n",
      "Epoch 61/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7733e-04 - accuracy: 1.0000\n",
      "Epoch 62/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.7144e-04 - accuracy: 1.0000\n",
      "Epoch 63/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.6756e-04 - accuracy: 1.0000\n",
      "Epoch 64/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.6890e-04 - accuracy: 1.0000\n",
      "Epoch 65/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.6932e-04 - accuracy: 1.0000\n",
      "Epoch 66/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.5778e-04 - accuracy: 1.0000\n",
      "Epoch 67/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.6150e-04 - accuracy: 1.0000\n",
      "Epoch 68/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.5653e-04 - accuracy: 1.0000\n",
      "Epoch 69/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.5331e-04 - accuracy: 1.0000\n",
      "Epoch 70/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.5000e-04 - accuracy: 1.0000\n",
      "Epoch 71/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.5044e-04 - accuracy: 1.0000\n",
      "Epoch 72/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.4388e-04 - accuracy: 1.0000\n",
      "Epoch 73/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.4356e-04 - accuracy: 1.0000\n",
      "Epoch 74/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.4602e-04 - accuracy: 1.0000\n",
      "Epoch 75/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.3705e-04 - accuracy: 1.0000\n",
      "Epoch 76/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.4081e-04 - accuracy: 1.0000\n",
      "Epoch 77/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.3763e-04 - accuracy: 1.0000\n",
      "Epoch 78/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.3451e-04 - accuracy: 1.0000\n",
      "Epoch 79/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.3133e-04 - accuracy: 1.0000\n",
      "Epoch 80/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.3245e-04 - accuracy: 1.0000\n",
      "Epoch 81/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.2878e-04 - accuracy: 1.0000\n",
      "Epoch 82/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.2485e-04 - accuracy: 1.0000\n",
      "Epoch 83/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.2520e-04 - accuracy: 1.0000\n",
      "Epoch 84/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.2157e-04 - accuracy: 1.0000\n",
      "Epoch 85/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.2057e-04 - accuracy: 1.0000\n",
      "Epoch 86/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.1735e-04 - accuracy: 1.0000\n",
      "Epoch 87/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.1576e-04 - accuracy: 1.0000\n",
      "Epoch 88/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.1502e-04 - accuracy: 1.0000\n",
      "Epoch 89/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.1382e-04 - accuracy: 1.0000\n",
      "Epoch 90/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.1132e-04 - accuracy: 1.0000\n",
      "Epoch 91/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.0988e-04 - accuracy: 1.0000\n",
      "Epoch 92/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.0744e-04 - accuracy: 1.0000\n",
      "Epoch 93/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.1148e-04 - accuracy: 1.0000\n",
      "Epoch 94/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.0544e-04 - accuracy: 1.0000\n",
      "Epoch 95/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.0226e-04 - accuracy: 1.0000\n",
      "Epoch 96/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.0695e-04 - accuracy: 1.0000\n",
      "Epoch 97/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.1220e-04 - accuracy: 1.0000\n",
      "Epoch 98/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.0091e-04 - accuracy: 1.0000\n",
      "Epoch 99/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.9633e-04 - accuracy: 1.0000\n",
      "Epoch 100/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.9729e-04 - accuracy: 1.0000\n",
      "Epoch 101/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.9549e-04 - accuracy: 1.0000\n",
      "Epoch 102/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.9308e-04 - accuracy: 1.0000\n",
      "Epoch 103/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8986e-04 - accuracy: 1.0000\n",
      "Epoch 104/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8950e-04 - accuracy: 1.0000\n",
      "Epoch 105/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8757e-04 - accuracy: 1.0000\n",
      "Epoch 106/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8612e-04 - accuracy: 1.0000\n",
      "Epoch 107/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8589e-04 - accuracy: 1.0000\n",
      "Epoch 108/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8225e-04 - accuracy: 1.0000\n",
      "Epoch 109/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8152e-04 - accuracy: 1.0000\n",
      "Epoch 110/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.7982e-04 - accuracy: 1.0000\n",
      "Epoch 111/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8093e-04 - accuracy: 1.0000\n",
      "Epoch 112/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8109e-04 - accuracy: 1.0000\n",
      "Epoch 113/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.7786e-04 - accuracy: 1.0000\n",
      "Epoch 114/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.7411e-04 - accuracy: 1.0000\n",
      "Epoch 115/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.7241e-04 - accuracy: 1.0000\n",
      "Epoch 116/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.7037e-04 - accuracy: 1.0000\n",
      "Epoch 117/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.7114e-04 - accuracy: 1.0000\n",
      "Epoch 118/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.7025e-04 - accuracy: 1.0000\n",
      "Epoch 119/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.6737e-04 - accuracy: 1.0000\n",
      "Epoch 120/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.6644e-04 - accuracy: 1.0000\n",
      "Epoch 121/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.6753e-04 - accuracy: 1.0000\n",
      "Epoch 122/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.6560e-04 - accuracy: 1.0000\n",
      "Epoch 123/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.6487e-04 - accuracy: 1.0000\n",
      "Epoch 124/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.6022e-04 - accuracy: 1.0000\n",
      "Epoch 125/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.6091e-04 - accuracy: 1.0000\n",
      "Epoch 126/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.5924e-04 - accuracy: 1.0000\n",
      "Epoch 127/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.5770e-04 - accuracy: 1.0000\n",
      "Epoch 128/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.5654e-04 - accuracy: 1.0000\n",
      "Epoch 129/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.5535e-04 - accuracy: 1.0000\n",
      "Epoch 130/130\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.5470e-04 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9841\n",
      "\n",
      " accracy : 0.9841\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(0)\n",
    "# tf.random.set_seed(3)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = seed )# seed)\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 130, batch_size = 5)\n",
    "\n",
    "print(\"\\n accracy : %.04f\" % (model.evaluate(x_test, y_test)[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "legitimate-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('overfit_model.h5') # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "exposed-hayes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9841\n",
      "\n",
      " accracy : 0.9841\n"
     ]
    }
   ],
   "source": [
    "# model = load_model('./overfit_model.h5') # 모델 사용 \n",
    "\n",
    "print(\"\\n accracy : %.04f\" % (model.evaluate(x_test, y_test)[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eligible-closure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.1984e-07 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.1239e-07 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.0951e-07 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.0139e-07 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.9466e-07 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.8707e-07 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.8502e-07 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.7628e-07 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.7334e-07 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.7061e-07 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.6264e-07 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.5600e-07 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.5233e-07 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.4671e-07 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.4233e-07 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.4043e-07 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.3006e-07 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.2700e-07 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.2600e-07 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.1633e-07 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.1231e-07 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.1296e-07 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.0595e-07 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.0004e-07 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.9882e-07 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.9496e-07 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.9270e-07 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.9209e-07 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.8602e-07 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.7851e-07 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.7654e-07 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.7233e-07 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.6976e-07 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.6658e-07 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.6197e-07 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.5781e-07 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.5488e-07 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.5623e-07 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.4957e-07 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.4606e-07 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.4108e-07 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.3853e-07 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.3420e-07 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.3539e-07 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.3401e-07 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.2692e-07 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.2248e-07 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.1916e-07 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.1864e-07 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.1630e-07 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.0984e-07 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.1097e-07 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.0621e-07 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.0087e-07 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.0494e-07 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.9498e-07 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.9174e-07 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.8840e-07 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.8667e-07 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.8169e-07 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.7878e-07 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.7874e-07 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.7404e-07 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.7251e-07 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.7003e-07 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.6772e-07 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.6376e-07 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.5945e-07 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.5736e-07 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.5562e-07 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.5051e-07 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.5149e-07 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.4569e-07 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.4436e-07 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.4443e-07 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.4312e-07 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.4518e-07 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.3329e-07 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.3670e-07 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.3169e-07 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.2968e-07 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.2424e-07 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.2275e-07 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.1912e-07 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.1991e-07 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.1947e-07 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.1665e-07 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.1052e-07 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.0781e-07 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.0860e-07 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.0535e-07 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.0247e-07 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9882e-07 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9784e-07 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9463e-07 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9373e-07 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9039e-07 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9085e-07 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.8627e-07 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.8860e-07 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8823e-07 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.0882e-07 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9158e-07 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.8405e-07 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.8107e-07 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.8031e-07 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7580e-07 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7504e-07 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7297e-07 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6951e-07 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6668e-07 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6499e-07 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6578e-07 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5865e-07 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5912e-07 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5845e-07 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5567e-07 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5220e-07 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5009e-07 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4901e-07 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4568e-07 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4719e-07 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4460e-07 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4274e-07 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4108e-07 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4177e-07 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3682e-07 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4010e-07 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3854e-07 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3251e-07 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3212e-07 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3118e-07 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2950e-07 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2745e-07 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2613e-07 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2527e-07 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2223e-07 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2336e-07 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1975e-07 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2118e-07 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1739e-07 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1630e-07 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1814e-07 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1490e-07 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1296e-07 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1410e-07 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1191e-07 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1090e-07 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0901e-07 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0582e-07 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0698e-07 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0521e-07 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0562e-07 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0398e-07 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0233e-07 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0042e-07 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0059e-07 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.8700e-08 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.9599e-08 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.7308e-08 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0051e-07 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.6484e-08 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.5201e-08 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.3499e-08 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.3446e-08 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.4770e-08 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.2966e-08 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.0826e-08 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.9022e-08 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.9175e-08 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.7474e-08 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.7924e-08 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.7990e-08 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.3973e-08 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.4825e-08 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.4565e-08 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.3808e-08 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.6772e-08 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.0582e-08 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 5.9533e-09 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-5322f563f416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mk_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m   return pack_sequence_as(\n\u001b[0m\u001b[1;32m    635\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   \"\"\"\n\u001b[0;32m--> 570\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m     final_index, packed = _packed_nest_with_indices(structure, flat_sequence,\n\u001b[0m\u001b[1;32m    523\u001b[0m                                                     0, is_seq, sequence_fn)\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_packed_nest_with_indices\u001b[0;34m(structure, flat, index, is_seq, sequence_fn)\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m       \u001b[0mpacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m       \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 교차검증\n",
    "n_fold = 10\n",
    "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = seed)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for train, test in skf.split(x, y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim = 60, activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.fit(x[train], y[train], epochs = 100, batch_size = 5)\n",
    "    k_accuracy = \"%.4f\" % (model.evaluate(x[test], y[test])[1])\n",
    "    accuracy.append(k_accuracy)\n",
    "    \n",
    "print(\"\\n %.f fold accracy : %.04f\" % (n_fold, accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-idaho",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
